{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a6848a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import crypten\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c846e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data_samples/2/train\n",
    "!mkdir data_samples/2/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d597ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root = '../../../datasets/mnist', \n",
    "                                         download = True, \n",
    "                                         train = True, \n",
    "                                         transform = transform)\n",
    "mnist_val = torchvision.datasets.MNIST(root = '../../../datasets/mnist', \n",
    "                                       download = True, \n",
    "                                       train = False, \n",
    "                                       transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f630150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "mnist_train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "mnist_val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "835801c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(dataloader):\n",
    "    \n",
    "    X_all = torch.tensor([])\n",
    "    y_all = torch.tensor([])\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        X, y = data\n",
    "        X_all = torch.cat((X, X_all), dim = 0)\n",
    "        y_all = torch.cat((y, y_all), dim = 0)\n",
    "            \n",
    "    return X_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8a3054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data, mnist_train_targets = extract(mnist_train_dataloader)\n",
    "mnist_val_data, mnist_val_targets = extract(mnist_val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0b2d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_targets_shuffled, mnist_train_data_shuffled = sklearn.utils.shuffle(mnist_train_targets, \n",
    "                                                                                mnist_train_data)\n",
    "mnist_val_targets_shuffled, mnist_val_data_shuffled = sklearn.utils.shuffle(mnist_val_targets, \n",
    "                                                                            mnist_val_data)\n",
    "num_parties = 2\n",
    "\n",
    "mnist_train_targets_shuffled_split = np.split(mnist_train_targets_shuffled, num_parties)\n",
    "mnist_train_data_shuffled_split = np.split(mnist_train_data_shuffled, num_parties)\n",
    "\n",
    "mnist_val_targets_shuffled_split = np.split(mnist_val_targets_shuffled, num_parties)\n",
    "mnist_val_data_shuffled_split = np.split(mnist_val_data_shuffled, num_parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14573778",
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in range(num_parties):\n",
    "    torch.save(mnist_train_targets_shuffled_split[party], f\"./data_samples/{num_parties}/train/targets_{party}.pth\")\n",
    "    torch.save(mnist_train_data_shuffled_split[party], f\"./data_samples/{num_parties}/train/data_{party}.pth\")\n",
    "    torch.save(mnist_val_targets_shuffled_split[party], f\"./data_samples/{num_parties}/val/targets_{party}.pth\")\n",
    "    torch.save(mnist_val_data_shuffled_split[party], f\"./data_samples/{num_parties}/val/data_{party}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5f4e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/alexder/anaconda3/envs/cs356v2/lib/python3.9/site-packages/crypten/__init__.py:64: RuntimeWarning: CrypTen is already initialized.\n",
      "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "crypten.init()\n",
    "ALICE = 1\n",
    "BOB = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fac6c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.arange(len(mnist_train))\n",
    "val_indices = np.arange(len(mnist_val))\n",
    "\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(val_indices)\n",
    "\n",
    "alice_train_indices = train_indices[:int(len(train_indices)/2)]\n",
    "bob_train_indices = train_indices[int(len(train_indices)/2):]\n",
    "\n",
    "alice_val_indices = val_indices[:int(len(val_indices)/2)]\n",
    "bob_val_indices = val_indices[int(len(val_indices)/2):]\n",
    "\n",
    "alice_train_dataset = torch.utils.data.Subset(mnist_train, alice_train_indices)\n",
    "bob_train_dataset = torch.utils.data.Subset(mnist_train, bob_train_indices)\n",
    "\n",
    "alice_val_dataset = torch.utils.data.Subset(mnist_val, alice_val_indices)\n",
    "bob_val_dataset = torch.utils.data.Subset(mnist_val, bob_val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d066975",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(alice_train_dataset, './data_samples/alice_train_dataset.pth')\n",
    "torch.save(bob_val_dataset, './data_samples/bob_val_dataset.pth')\n",
    "torch.save(alice_train_dataset, './data_samples/alice_train_dataset.pth')\n",
    "torch.save(bob_val_dataset, './data_samples/bob_val_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8102f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_dataloader_train = torch.utils.data.DataLoader(dataset = alice_train_dataset, batch_size = batch_size, shuffle = True)\n",
    "bob_dataloader_train = torch.utils.data.DataLoader(dataset = bob_train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "alice_dataloader_val = torch.utils.data.DataLoader(dataset = alice_val_dataset, batch_size = batch_size, shuffle = True)\n",
    "bob_dataloader_val = torch.utils.data.DataLoader(dataset = bob_val_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0d3ef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph encrypted module"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Step. Initialize an encypted ResNet model\n",
    "\n",
    "resnet18_plaintext = torchvision.models.resnet18()\n",
    "dummy_input = torch.empty((64, 3, 7, 7))\n",
    "\n",
    "model_enc = crypten.nn.from_pytorch(resnet18_plaintext, dummy_input)\n",
    "model_enc.encrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_alice_enc = crypten.load_from_party('/data_samples/alice_train_dataset.pth', src=ALICE)\n",
    "x_alice_enc = crypten.load_from_party('/data_samples/alice_train_dataset.pth', src=ALICE)\n",
    "x_bob_enc = crypten.load_from_party('/tmp/bob_train.pth', src=BOB)\n",
    "\n",
    "crypten.print(x_alice_enc.size())\n",
    "crypten.print(x_bob_enc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334a37b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playground.ipynb  tutorials\r\n"
     ]
    }
   ],
   "source": [
    "model_enc.train()\n",
    "loss = crypten.nn.MSELoss() \n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "\n",
    "# Train the model: SGD on encrypted data\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    # forward pass\n",
    "    output = model_enc(x_train)\n",
    "    loss_value = loss(output, y_train)\n",
    "    \n",
    "    # set gradients to zero\n",
    "    model.zero_grad()\n",
    "\n",
    "    # perform backward pass\n",
    "    loss_value.backward()\n",
    "\n",
    "    # update parameters\n",
    "    model.update_parameters(learning_rate) \n",
    "    \n",
    "    # examine the loss after each epoch\n",
    "    print(\"Epoch: {0:d} Loss: {1:.4f}\".format(i, loss_value.get_plain_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc962c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
